{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QhNj18oeA3Eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073acd7c-4273-4b8f-cc0e-6639e50d2e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 100 x 100, CPU average execution time: 0.00017719268798828126 seconds, GPU average execution time: 0.27927846908569337 seconds\n",
            "Matrix size: 200 x 200, CPU average execution time: 0.0005606651306152344 seconds, GPU average execution time: 0.0009641647338867188 seconds\n",
            "Matrix size: 500 x 500, CPU average execution time: 0.007305669784545899 seconds, GPU average execution time: 0.0039574623107910155 seconds\n",
            "Matrix size: 1000 x 1000, CPU average execution time: 0.06612677574157715 seconds, GPU average execution time: 0.028873586654663087 seconds\n",
            "Matrix size: 2000 x 2000, CPU average execution time: 0.5013725996017456 seconds, GPU average execution time: 0.09917869567871093 seconds\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "sizes = [100, 200, 500, 1000, 2000]   # اندازه‌های مختلف ماتریس‌ها\n",
        "\n",
        "for size in sizes:\n",
        "    a_cpu = np.random.rand(size, size)\n",
        "    b_cpu = np.random.rand(size, size)\n",
        "\n",
        "    a_gpu = cp.asarray(a_cpu)\n",
        "    b_gpu = cp.asarray(b_cpu)\n",
        "\n",
        "    cpu_times = []\n",
        "    gpu_times = []\n",
        "    for i in range(10):   # اجرای تابع ۱۰ بار برای محاسبه میانگین زمان اجرا\n",
        "        start_time = time.time()\n",
        "        c_cpu = np.dot(a_cpu, b_cpu)\n",
        "        end_time = time.time()\n",
        "\n",
        "        cpu_times.append(end_time - start_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        c_gpu = cp.matmul(a_gpu, b_gpu)\n",
        "        cp.cuda.Stream.null.synchronize()   # همگام‌سازی برای انتظار پایان اجرای تابع\n",
        "        end_time = time.time()\n",
        "\n",
        "        gpu_times.append(end_time - start_time)\n",
        "\n",
        "    cpu_avg_time = sum(cpu_times) / len(cpu_times)\n",
        "    gpu_avg_time = sum(gpu_times) / len(gpu_times)\n",
        "    print(f\"Matrix size: {size} x {size}, CPU average execution time: {cpu_avg_time} seconds, GPU average execution time: {gpu_avg_time} seconds\")"
      ]
    }
  ]
}